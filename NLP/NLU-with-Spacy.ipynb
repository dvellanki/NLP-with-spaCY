{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c517d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fecb9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84be6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The rain in Spain falls mainly on the plain.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff1da1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET True\n",
      "rain rain NOUN False\n",
      "in in ADP True\n",
      "Spain Spain PROPN False\n",
      "falls fall VERB False\n",
      "mainly mainly ADV False\n",
      "on on ADP True\n",
      "the the DET True\n",
      "plain plain NOUN False\n",
      ". . PUNCT False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cae839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     text   lemma    POS      explain  stopword\n",
      "0     The     the    DET   determiner      True\n",
      "1    rain    rain   NOUN         noun     False\n",
      "2      in      in    ADP   adposition      True\n",
      "3   Spain   Spain  PROPN  proper noun     False\n",
      "4   falls    fall   VERB         verb     False\n",
      "5  mainly  mainly    ADV       adverb     False\n",
      "6      on      on    ADP   adposition      True\n",
      "7     the     the    DET   determiner      True\n",
      "8   plain   plain   NOUN         noun     False\n",
      "9       .       .  PUNCT  punctuation     False\n"
     ]
    }
   ],
   "source": [
    "cols = (\"text\", \"lemma\", \"POS\", \"explain\", \"stopword\")\n",
    "rows = []\n",
    "for t in doc:\n",
    "    row = [t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c7f5e",
   "metadata": {},
   "source": [
    "#### \n",
    "For each word in that sentence spaCy has created a token, to show:\n",
    "raw text\n",
    "lemma â€“ a root form of the word\n",
    "part of speech\n",
    "a flag for whether the word is a stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6db77",
   "metadata": {},
   "source": [
    "### Visualize the parse tree for this sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50530df1",
   "metadata": {},
   "source": [
    "#### This visualization shows the predictions from the loaded spaCy model. \n",
    "#### When you load a model, like en_core_web_sm, you load a pipeline of models that spaCy runs on your behalf. \n",
    "#### One of these models is called the \"tagger,\" and it predicts linguistic features for all of the tokens. \n",
    "#### The tagger is the model that indicates that \"spaCy\" is a proper noun (PROPN) in the sentence above, and that \"handles\" is a verb (VERB). The visualization also shows the syntactic dependencies between the tokens.\n",
    "#### Another model in the spaCy pipeline, the \"parser\", is responsible for predicting this grammatical structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db81c3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"de64a711409f4d6987e4d4ab9591a6f7-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">rain</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Spain</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">falls</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">mainly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">plain.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de64a711409f4d6987e4d4ab9591a6f7-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de64a711409f4d6987e4d4ab9591a6f7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de64a711409f4d6987e4d4ab9591a6f7-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de64a711409f4d6987e4d4ab9591a6f7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de64a711409f4d6987e4d4ab9591a6f7-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de64a711409f4d6987e4d4ab9591a6f7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de64a711409f4d6987e4d4ab9591a6f7-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de64a711409f4d6987e4d4ab9591a6f7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de64a711409f4d6987e4d4ab9591a6f7-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de64a711409f4d6987e4d4ab9591a6f7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de64a711409f4d6987e4d4ab9591a6f7-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de64a711409f4d6987e4d4ab9591a6f7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de64a711409f4d6987e4d4ab9591a6f7-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de64a711409f4d6987e4d4ab9591a6f7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-de64a711409f4d6987e4d4ab9591a6f7-0-7\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-de64a711409f4d6987e4d4ab9591a6f7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1445.0,266.5 L1453.0,254.5 1437.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5d5b6",
   "metadata": {},
   "source": [
    "### Handling multiple sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b58826dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> We were all out at the zoo one day, I was doing some acting, walking on the railing of the gorilla exhibit.\n",
      "> I fell in.\n",
      "> Everyone screamed and Tommy jumped in after me, forgetting that he had blueberries in his front pocket.\n",
      "> The gorillas just went wild.\n"
     ]
    }
   ],
   "source": [
    "text = \"We were all out at the zoo one day, I was doing some acting, walking on the railing of the gorilla exhibit. I fell in.Everyone screamed and Tommy jumped in after me, forgetting that he had blueberries in his front pocket. The gorillas just went wild.\"\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    print(\">\", sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c3b80",
   "metadata": {},
   "source": [
    "#### spaCy doesn't carve the text stream into little pieces. So each sentence is a span with a start and an end index into the document array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "667228b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0 25\n",
      "> 25 29\n",
      "> 29 48\n",
      "> 48 54\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(\">\", sent.start, sent.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbc11086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The gorillas just went wild."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pull out tokens for one sentence\n",
    "doc[48:54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5117179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went go VERB\n"
     ]
    }
   ],
   "source": [
    "##index into a specific token\n",
    "token = doc[51]\n",
    "print(token.text, token.lemma_, token.pos_)\n",
    "\n",
    "## the lemma for the word went is go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66a995",
   "metadata": {},
   "source": [
    "### Getting texts using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a838bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f0e029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "126e3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "##find and extract text from <p> tags\n",
    "def get_text (url):\n",
    "    buf = []\n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "        for p in soup.find_all(\"p\"):\n",
    "            buf.append(p.get_text())\n",
    "        return \"\".join(buf)\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "        sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "704542d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SPDX short identifier: BSD-3-Clause Note: This license has also been called the \"New BSD License\" or \"Modified BSD License\".\n",
      "> See also the 2-clause BSD License.\n",
      "> Copyright <YEAR> <COPYRIGHT HOLDER>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:1.\n",
      "> Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.3.\n",
      "> Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
      "> THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\n",
      "> CONTRIBUTORS\n",
      "> \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n",
      "> IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n",
      "> HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.For over 20 years the Open Source Initiative (OSI) has worked to raise awareness and adoption of open source software, and build bridges between open source communities of practice.\n",
      "> As a global non-profit, the OSI champions software freedom in society through education, collaboration, and infrastructure, stewarding the Open Source Definition (OSD), and preventing abuse of the ideals and ethos inherent to the open source movement.\n",
      "> Open source software is made by many people and distributed under an OSD-compliant license which grants all the rights to use, study, change, and share the software in modified and unmodified form.\n",
      "> Software freedom is essential to enabling community development of open source software.\n",
      ">    Sign-up for our newsletter!The content on this website, of which Opensource.org is the author, is licensed under a Creative Commons Attribution 4.0 International License.\n",
      "> \n",
      "Opensource.org is not the author of any of the licenses reproduced on this site.\n",
      "> Questions about the copyright in a license should be directed to the license steward.\n",
      "> Hosting for Opensource.org is generously provided by DigitalOcean.\n",
      "> Please see Terms of Service.\n",
      "> For questions regarding the OSI website and contents pleasee email our webmaster.\n",
      ">  \n"
     ]
    }
   ],
   "source": [
    "lic = {}\n",
    "lic[\"mit\"] = nlp(get_text(\"https://opensource.org/licenses/MIT\"))\n",
    "lic[\"asl\"] = nlp(get_text(\"https://opensource.org/licenses/Apache-20\"))\n",
    "lic[\"bsd\"] = nlp(get_text(\"https://opensource.org/licenses/BSD-3-Clause\"))\n",
    "\n",
    "for sent in lic[\"bsd\"].sents:\n",
    "    print(\">\", sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c9af5",
   "metadata": {},
   "source": [
    "#### Comparing the similarity metrics in the text found from open sources above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "120a66c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mit asl 0.7416972794190073\n",
      "asl bsd 0.7637987327062771\n",
      "bsd mit 0.9773236055944917\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    [\"mit\", \"asl\"],\n",
    "    [\"asl\", \"bsd\"],\n",
    "    [\"bsd\", \"mit\"]]\n",
    "\n",
    "for a, b in pairs:\n",
    "    print(a, b, lic[a].similarity(lic[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8ef7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BSD and MIT appaear to be almost similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563295ff",
   "metadata": {},
   "source": [
    "### Natural Language Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "515c99de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs\n",
      "Steve Wozniak\n",
      "Apple Computer\n",
      "January\n",
      "Cupertino\n",
      "California\n"
     ]
    }
   ],
   "source": [
    "## get noun checks \n",
    "text = \"Steve Jobs and Steve Wozniak incorporated Apple Computer on January 3, 1977, in Cupertino, California.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61660865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs PERSON\n",
      "Steve Wozniak PERSON\n",
      "Apple Computer ORG\n",
      "January 3, 1977 DATE\n",
      "Cupertino GPE\n",
      "California GPE\n"
     ]
    }
   ],
   "source": [
    "## get named entities (proper nouns)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd568d3",
   "metadata": {},
   "source": [
    "#### Visualizing the named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1cb91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Jobs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Wozniak\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " incorporated \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple Computer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    January 3, 1977\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cupertino\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    California\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f70142b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Knowledge graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5497a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dvellanki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3f62af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "after ['tok2vec', 'tagger', 'spacy_wordnet', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "## Customizing the pipeline\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator\n",
    "print(\"before\", nlp.pipe_names)\n",
    "if \"WordnetAnnotator\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"spacy_wordnet\", after=\"tagger\")\n",
    "    print(\"after\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Click through the results online in a WordNet search to find the meanings related to the word withdraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "046e4c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('withdraw.v.01'),\n",
       " Synset('retire.v.02'),\n",
       " Synset('disengage.v.01'),\n",
       " Synset('recall.v.07'),\n",
       " Synset('swallow.v.05'),\n",
       " Synset('seclude.v.01'),\n",
       " Synset('adjourn.v.02'),\n",
       " Synset('bow_out.v.02'),\n",
       " Synset('withdraw.v.09'),\n",
       " Synset('retire.v.08'),\n",
       " Synset('retreat.v.04'),\n",
       " Synset('remove.v.01')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nlp(\"withdraw\")[0]\n",
    "token._.wordnet.synsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d7b0b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('withdraw.v.01.withdraw'),\n",
       " Lemma('withdraw.v.01.retreat'),\n",
       " Lemma('withdraw.v.01.pull_away'),\n",
       " Lemma('withdraw.v.01.draw_back'),\n",
       " Lemma('withdraw.v.01.recede'),\n",
       " Lemma('withdraw.v.01.pull_back'),\n",
       " Lemma('withdraw.v.01.retire'),\n",
       " Lemma('withdraw.v.01.move_back'),\n",
       " Lemma('retire.v.02.retire'),\n",
       " Lemma('retire.v.02.withdraw'),\n",
       " Lemma('disengage.v.01.disengage'),\n",
       " Lemma('disengage.v.01.withdraw'),\n",
       " Lemma('recall.v.07.recall'),\n",
       " Lemma('recall.v.07.call_in'),\n",
       " Lemma('recall.v.07.call_back'),\n",
       " Lemma('recall.v.07.withdraw'),\n",
       " Lemma('swallow.v.05.swallow'),\n",
       " Lemma('swallow.v.05.take_back'),\n",
       " Lemma('swallow.v.05.unsay'),\n",
       " Lemma('swallow.v.05.withdraw'),\n",
       " Lemma('seclude.v.01.seclude'),\n",
       " Lemma('seclude.v.01.sequester'),\n",
       " Lemma('seclude.v.01.sequestrate'),\n",
       " Lemma('seclude.v.01.withdraw'),\n",
       " Lemma('adjourn.v.02.adjourn'),\n",
       " Lemma('adjourn.v.02.withdraw'),\n",
       " Lemma('adjourn.v.02.retire'),\n",
       " Lemma('bow_out.v.02.bow_out'),\n",
       " Lemma('bow_out.v.02.withdraw'),\n",
       " Lemma('withdraw.v.09.withdraw'),\n",
       " Lemma('withdraw.v.09.draw'),\n",
       " Lemma('withdraw.v.09.take_out'),\n",
       " Lemma('withdraw.v.09.draw_off'),\n",
       " Lemma('retire.v.08.retire'),\n",
       " Lemma('retire.v.08.withdraw'),\n",
       " Lemma('retreat.v.04.retreat'),\n",
       " Lemma('retreat.v.04.pull_back'),\n",
       " Lemma('retreat.v.04.back_out'),\n",
       " Lemma('retreat.v.04.back_away'),\n",
       " Lemma('retreat.v.04.crawfish'),\n",
       " Lemma('retreat.v.04.crawfish_out'),\n",
       " Lemma('retreat.v.04.pull_in_one's_horns'),\n",
       " Lemma('retreat.v.04.withdraw'),\n",
       " Lemma('remove.v.01.remove'),\n",
       " Lemma('remove.v.01.take'),\n",
       " Lemma('remove.v.01.take_away'),\n",
       " Lemma('remove.v.01.withdraw')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token._.wordnet.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d35804d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astronomy',\n",
       " 'school',\n",
       " 'telegraphy',\n",
       " 'industry',\n",
       " 'psychology',\n",
       " 'ethnology',\n",
       " 'ethnology',\n",
       " 'administration',\n",
       " 'school',\n",
       " 'finance',\n",
       " 'economy',\n",
       " 'exchange',\n",
       " 'banking',\n",
       " 'commerce',\n",
       " 'medicine',\n",
       " 'ethnology',\n",
       " 'university',\n",
       " 'school',\n",
       " 'buildings',\n",
       " 'factotum',\n",
       " 'agriculture',\n",
       " 'mechanics',\n",
       " 'gastronomy',\n",
       " 'meteorology',\n",
       " 'physics',\n",
       " 'basketball',\n",
       " 'anatomy',\n",
       " 'skiing',\n",
       " 'nautical',\n",
       " 'engineering',\n",
       " 'racing',\n",
       " 'home',\n",
       " 'drawing',\n",
       " 'dentistry',\n",
       " 'ethnology',\n",
       " 'mathematics',\n",
       " 'furniture',\n",
       " 'animal_husbandry',\n",
       " 'industry',\n",
       " 'economy',\n",
       " 'body_care',\n",
       " 'chemistry',\n",
       " 'medicine',\n",
       " 'surgery',\n",
       " 'vehicles',\n",
       " 'transport',\n",
       " 'atomic_physic',\n",
       " 'archaeology',\n",
       " 'hydraulics',\n",
       " 'oceanography',\n",
       " 'golf',\n",
       " 'sculpture',\n",
       " 'earth',\n",
       " 'applied_science',\n",
       " 'artisanship']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token._.wordnet.wordnet_domains()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7fe0cd",
   "metadata": {},
   "source": [
    "#### NLU results that are within Finance and Banking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef6c0bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I (deprivation|neediness|want|privation) (deprivation|want|lack|neediness|privation|deficiency) (deprivation|want|lack|need|require|neediness|privation|deficiency) to (draw|draw_off|take_out|withdraw) 5,000 euros .\n"
     ]
    }
   ],
   "source": [
    "domains = [\"finance\", \"banking\"]\n",
    "sentence = nlp(\"I want to withdraw 5,000 euros.\")\n",
    "\n",
    "enriched_sent = []\n",
    "\n",
    "for token in sentence:\n",
    "    # get synsets within the desired domains\n",
    "    synsets = token._.wordnet.wordnet_synsets_for_domain(domains)\n",
    "\n",
    "    if synsets:\n",
    "        lemmas_for_synset = []\n",
    "\n",
    "        for s in synsets:\n",
    "        # get synset variants and add to the enriched sentence\n",
    "            lemmas_for_synset.extend(s.lemma_names())\n",
    "            enriched_sent.append(\"({})\".format(\"|\".join(set(lemmas_for_synset))))\n",
    "    else:\n",
    "        enriched_sent.append(token.text)\n",
    "print(\" \".join(enriched_sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
